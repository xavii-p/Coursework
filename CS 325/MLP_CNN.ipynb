{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1**\n",
        "\n",
        "*MLP Model Structure*:\n",
        "     Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        "\n",
        "      flatten (Flatten)           (None, 784)               0         \n",
        "\n",
        "      dense (Dense)               (None, 128)               100480    \n",
        "                                                                 \n",
        "      dense_1 (Dense)             (None, 128)               16512     \n",
        "\n",
        "      dense_2 (Dense)             (None, 10)                1290\n",
        "\n",
        "\n",
        "*MLP Accuracy*:\n",
        "`Test accuracy:  0.7924000024795532`\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*CNN Model Structure*:\n",
        "      Layer (type)                    Output Shape              Param #   \n",
        "=================================================================\n",
        "\n",
        "      conv2d_2 (Conv2D)               (None, 28, 28, 32)        320       \n",
        "                                                                 \n",
        "      max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 32)        0    \n",
        "\n",
        "                                                                 \n",
        "      conv2d_3 (Conv2D)               (None, 14, 14, 64)        18496     \n",
        "                                                                 \n",
        "      max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 64)          0         \n",
        "                                                            \n",
        "                                                                 \n",
        "      flatten_2 (Flatten)             (None, 3136)              0         \n",
        "                                                                 \n",
        "      dense_5 (Dense)                 (None, 128)               401536    \n",
        "                                                                 \n",
        "      dense_6 (Dense)                 (None, 10)                1290      \n",
        "                                                                 \n",
        "\n",
        "\n",
        "*CNN Accuracy*:\n",
        "`Test accuracy: 0.9190000295639038`"
      ],
      "metadata": {
        "id": "_UHrTOtJq7oJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "Cm-dlxYIZgEm",
        "outputId": "1eed8d0c-5a53-4e9b-b2e6-6359f390f021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118282 (462.04 KB)\n",
            "Trainable params: 118282 (462.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.7854 - accuracy: 0.8131\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.5583 - accuracy: 0.8460\n",
            "Epoch 3/10\n",
            " 659/1875 [=========>....................] - ETA: 4s - loss: 0.5148 - accuracy: 0.8539"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-eede6d3ffd7e>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m training_history = MLPmodel.fit(\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mtrainNormalized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mtrainLabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m   function = trace_function(\n\u001b[0m\u001b[1;32m    133\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     concrete_function = tracing_options.function_cache.lookup(\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_func_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_cache.py\u001b[0m in \u001b[0;36mlookup\u001b[0;34m(self, function_type, context)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mFunctionContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0mdispatch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdispatch_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_primary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdispatch_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/type_dispatch.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;34m\"\"\"Returns the most specific supertype target if it exists in the table.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# For known exact matches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_table\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__get_cmp_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m       setattr(self, _CACHED_CMP_KEY, (\n\u001b[1;32m    605\u001b[0m           \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       ))\n\u001b[1;32m    608\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_CACHED_CMP_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    624\u001b[0m       ])\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    624\u001b[0m       ])\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    624\u001b[0m       ])\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    624\u001b[0m       ])\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    610\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;34m\"\"\"Converts `value` to a hashable key.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m     if isinstance(value, (int, float, bool, np.generic, dtypes.DType, TypeSpec,\n\u001b[0m\u001b[1;32m    613\u001b[0m                           tensor_shape.TensorShape)):\n\u001b[1;32m    614\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import datetime\n",
        "import platform\n",
        "\n",
        "'''\n",
        "PART 1\n",
        "'''\n",
        "\n",
        "# load data\n",
        "mnist_dataset = tf.keras.datasets.fashion_mnist\n",
        "(trainData, trainLabels), (testData, testLabels) = mnist_dataset.load_data()\n",
        "\n",
        "\n",
        "## normalize\n",
        "trainNormalized = trainData / 255\n",
        "testNormalized = testData / 255\n",
        "\n",
        "log_dir=\".logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "\n",
        "# build MLP model with 3 layers\n",
        "MLPmodel = tf.keras.models.Sequential()\n",
        "#Flatten\n",
        "MLPmodel.add(tf.keras.layers.Flatten(input_shape=trainNormalized.shape[1:]))\n",
        "\n",
        "#Layer 1\n",
        "MLPmodel.add(tf.keras.layers.Dense(\n",
        "    units=128,\n",
        "    activation=tf.keras.activations.relu,\n",
        "    kernel_regularizer=tf.keras.regularizers.l2(0.002)\n",
        "))\n",
        "\n",
        "# Hidden layer\n",
        "MLPmodel.add(tf.keras.layers.Dense(\n",
        "    units=128,\n",
        "    activation=tf.keras.activations.relu,\n",
        "    kernel_regularizer=tf.keras.regularizers.l2(0.002)\n",
        "))\n",
        "\n",
        "# Output layer\n",
        "MLPmodel.add(tf.keras.layers.Dense(\n",
        "    units=10, # number of labels\n",
        "    activation=tf.keras.activations.softmax\n",
        "))\n",
        "\n",
        "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# Model summary\n",
        "MLPmodel.summary()\n",
        "\n",
        "MLPmodel.compile(\n",
        "    optimizer=adam_optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "training_history = MLPmodel.fit(\n",
        "    trainNormalized,\n",
        "    trainLabels,\n",
        "    epochs=10,\n",
        "    callbacks=[tensorboard_callback]\n",
        ")\n",
        "\n",
        "# Test accuracy\n",
        "testAcc = MLPmodel.evaluate(testNormalized, testLabels)[1]\n",
        "print('Test accuracy: ', testAcc)\n",
        "\n",
        "\n",
        "\n",
        "# Save\n",
        "model_name = 'mlp_fashion_mnist.h5'\n",
        "MLPmodel.save(model_name, save_format='h5')\n",
        "\n",
        "# build CNN model\n",
        "CNNmodel = tf.keras.models.Sequential()\n",
        "\n",
        "#2D Convolution layer - 32 filters, 3x3 kernel, ReLU activation, padding with same values\n",
        "CNNmodel.add(tf.keras.layers.Conv2D(\n",
        "    filters = 32,\n",
        "    kernel_size = (3,3),\n",
        "    padding='same',\n",
        "    activation=tf.keras.activations.relu,\n",
        "    data_format='channels_last',\n",
        "    input_shape=(28, 28, 1),\n",
        "))\n",
        "\n",
        "#Max pooling layer - 2x2 kernel, 2 stride\n",
        "CNNmodel.add(tf.keras.layers.MaxPool2D(\n",
        "    pool_size=(2, 2),\n",
        "    strides=2,\n",
        "    padding='valid',\n",
        "    data_format='channels_last',\n",
        "))\n",
        "\n",
        "#2D Convolution layer - 64 filters, 3x3 kernel, ReLU activation, padding with same values\n",
        "CNNmodel.add(tf.keras.layers.Conv2D(\n",
        "    filters = 64,\n",
        "    kernel_size = (3, 3),\n",
        "    padding='same',\n",
        "    activation=tf.keras.activations.relu,\n",
        "    data_format='channels_last',\n",
        "))\n",
        "\n",
        "#Max pooling layer - 2x2 kernel, 2 stride\n",
        "CNNmodel.add(tf.keras.layers.MaxPool2D(\n",
        "    pool_size=(2, 2),\n",
        "    strides=2,\n",
        "    padding='valid',\n",
        "    data_format='channels_last',\n",
        "))\n",
        "\n",
        "#Flatten layer\n",
        "CNNmodel.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#Dense layer - 128 nodes output, ReLU activation\n",
        "CNNmodel.add(tf.keras.layers.Dense(\n",
        "    units=128, # number of nodes\n",
        "    activation=tf.keras.activations.relu\n",
        "))\n",
        "#Dense layer - 10 nodes output, Softmax activation\n",
        "CNNmodel.add(tf.keras.layers.Dense(\n",
        "    units=10, # number of labels\n",
        "    activation=tf.keras.activations.softmax\n",
        "))\n",
        "\n",
        "# Model summary\n",
        "CNNmodel.summary()\n",
        "\n",
        "CNNmodel.compile(\n",
        "              optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "training_history = CNNmodel.fit(\n",
        "    trainNormalized,\n",
        "    trainLabels,\n",
        "    epochs=10,\n",
        "    callbacks=[tensorboard_callback],\n",
        ")\n",
        "\n",
        "# CNN Accuracy\n",
        "CNNAcc = CNNmodel.evaluate(testNormalized, testLabels)[1]\n",
        "print('Test Accuracy: ', CNNAcc)\n",
        "\n",
        "\n",
        "\n",
        "# Save\n",
        "model_name = 'cnn_fashion_mnist.h5'\n",
        "MLPmodel.save(model_name, save_format='h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART 2**\n",
        "\n",
        "*(Retrained) MLP Model Structure*:\n",
        "\n",
        "      Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        "\n",
        "      flatten_4 (Flatten)         (None, 3072)              0         \n",
        "                                                                 \n",
        "      dense_9 (Dense)             (None, 128)               393344    \n",
        "                                                                 \n",
        "      dense_10 (Dense)            (None, 128)               16512     \n",
        "                                                                 \n",
        "      dense_11 (Dense)            (None, 10)                1290      \n",
        "                                                                 \n",
        "\n",
        "*(Retrained) MLP Accuracy*:\n",
        "`Test accuracy:  0.4456000030040741`\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*(Retrained) CNN Model Structure*:\n",
        "\n",
        "      Layer (type)                    Output Shape              Param #   \n",
        "=================================================================\n",
        "\n",
        "      conv2d_4 (Conv2D)               (None, 32, 32, 32)        896       \n",
        "                                                                 \n",
        "      max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 32)        0         \n",
        "\n",
        "                                                                 \n",
        "      conv2d_5 (Conv2D)               (None, 16, 16, 64)        18496     \n",
        "                                                                 \n",
        "      max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 64)          0         \n",
        "\n",
        "                                                                 \n",
        "      flatten_3 (Flatten)             (None, 4096)              0         \n",
        "                                                                 \n",
        "      dense_7 (Dense)                 (None, 128)               524416    \n",
        "                                                                 \n",
        "      dense_8 (Dense)                 (None, 10)                1290      \n",
        "                                                                 \n",
        "*(Retrained) CNN Accuracy*:\n",
        "`Test accuracy:  0.713699996471405`\n",
        "\n",
        "*Specialized CNN Model Structure*:\n",
        "\n",
        "      Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        "\n",
        "      conv2d_6 (Conv2D)               (None, 30, 30, 32)        896       \n",
        "                                                                 \n",
        "      max_pooling2d_6 (MaxPooling2D)  (None, 15, 15, 32)        0         \n",
        "                                                             \n",
        "                                                                 \n",
        "      conv2d_7 (Conv2D)               (None, 13, 13, 64)        18496     \n",
        "                                                                 \n",
        "      max_pooling2d_7 (MaxPooling2D)  (None, 6, 6, 64)          0         \n",
        "                                                             \n",
        "                                                                 \n",
        "      conv2d_8 (Conv2D)               (None, 4, 4, 64)          36928     \n",
        "                                                                 \n",
        "      flatten_5 (Flatten)             (None, 1024)              0         \n",
        "                                                                 \n",
        "      dense_12 (Dense)                (None, 64)                65600     \n",
        "                                                                 \n",
        "      dense_13 (Dense)                (None, 10)                650       \n",
        "                                                                 \n",
        "\n",
        "*Specialized CNN Accuracy*:\n",
        "`Test accuracy: 0.7156000137329102`"
      ],
      "metadata": {
        "id": "TUg0y8Pt1o2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "PART 2\n",
        "'''\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# build MLP model with 3 layers\n",
        "retrainedMLP = tf.keras.models.Sequential()\n",
        "#Flatten\n",
        "retrainedMLP.add(tf.keras.layers.Flatten(input_shape=(32,32,3)))\n",
        "\n",
        "#Layer 1\n",
        "retrainedMLP.add(tf.keras.layers.Dense(\n",
        "    units=128,\n",
        "    activation=tf.keras.activations.relu,\n",
        "    kernel_regularizer=tf.keras.regularizers.l2(0.002)\n",
        "))\n",
        "\n",
        "# Hidden layer\n",
        "retrainedMLP.add(tf.keras.layers.Dense(\n",
        "    units=128,\n",
        "    activation=tf.keras.activations.relu,\n",
        "    kernel_regularizer=tf.keras.regularizers.l2(0.002)\n",
        "))\n",
        "\n",
        "# Output layer\n",
        "retrainedMLP.add(tf.keras.layers.Dense(\n",
        "    units=10, # number of labels\n",
        "    activation=tf.keras.activations.softmax\n",
        "))\n",
        "\n",
        "retrainedMLP.summary()\n",
        "\n",
        "retrainedMLP.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "training_history = retrainedMLP.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    callbacks=[tensorboard_callback],\n",
        ")\n",
        "\n",
        "# Retrained MLP Accuracy\n",
        "testAcc = retrainedMLP.evaluate(test_images, test_labels)[1]\n",
        "print('Test accuracy: ', testAcc)\n",
        "\n",
        "\n",
        "\n",
        "# build CNN model\n",
        "retrainedCNN = tf.keras.models.Sequential()\n",
        "\n",
        "#2D Convolution layer - 32 filters, 3x3 kernel, ReLU activation, padding with same values\n",
        "retrainedCNN.add(tf.keras.layers.Conv2D(\n",
        "    filters = 32,\n",
        "    kernel_size = (3,3),\n",
        "    padding='same',\n",
        "    activation=tf.keras.activations.relu,\n",
        "    data_format='channels_last',\n",
        "    input_shape=(32, 32, 3),\n",
        "))\n",
        "\n",
        "#Max pooling layer - 2x2 kernel, 2 stride\n",
        "retrainedCNN.add(tf.keras.layers.MaxPool2D(\n",
        "    pool_size=(2, 2),\n",
        "    strides=2,\n",
        "    padding='valid',\n",
        "    data_format='channels_last',\n",
        "))\n",
        "\n",
        "#2D Convolution layer - 64 filters, 3x3 kernel, ReLU activation, padding with same values\n",
        "retrainedCNN.add(tf.keras.layers.Conv2D(\n",
        "    filters = 64,\n",
        "    kernel_size = (3, 3),\n",
        "    padding='same',\n",
        "    activation=tf.keras.activations.relu,\n",
        "    data_format='channels_last',\n",
        "))\n",
        "\n",
        "#Max pooling layer - 2x2 kernel, 2 stride\n",
        "retrainedCNN.add(tf.keras.layers.MaxPool2D(\n",
        "    pool_size=(2, 2),\n",
        "    strides=2,\n",
        "    padding='valid',\n",
        "    data_format='channels_last',\n",
        "))\n",
        "\n",
        "#Flatten layer\n",
        "retrainedCNN.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#Dense layer - 128 nodes output, ReLU activation\n",
        "retrainedCNN.add(tf.keras.layers.Dense(\n",
        "    units=128, # number of nodes\n",
        "    activation=tf.keras.activations.relu\n",
        "))\n",
        "#Dense layer - 10 nodes output, Softmax activation\n",
        "retrainedCNN.add(tf.keras.layers.Dense(\n",
        "    units=10, # number of labels\n",
        "    activation=tf.keras.activations.softmax\n",
        "))\n",
        "\n",
        "retrainedCNN.summary()\n",
        "\n",
        "retrainedCNN.compile(\n",
        "              optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "training_history = retrainedCNN.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    callbacks=[tensorboard_callback],\n",
        ")\n",
        "\n",
        "# Retrained CNN Accuracy\n",
        "CNNAcc = retrainedCNN.evaluate(test_images, test_labels)[1]\n",
        "print('Test Accuracy: ', CNNAcc)\n",
        "\n",
        "\n",
        "# Build specialized CIFAR CNN\n",
        "CIFARmodel = tf.keras.models.Sequential()\n",
        "CIFARmodel.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "CIFARmodel.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "CIFARmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "CIFARmodel.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "CIFARmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "CIFARmodel.add(tf.keras.layers.Flatten())\n",
        "CIFARmodel.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "CIFARmodel.add(tf.keras.layers.Dense(10))\n",
        "\n",
        "CIFARmodel.summary()\n",
        "\n",
        "CIFARmodel.compile(\n",
        "              optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "training_history = CIFARmodel.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    validation_data=(test_images, test_labels),\n",
        "    callbacks=[tensorboard_callback],\n",
        ")\n",
        "\n",
        "# Specialized CIFAR CNN Accuracy\n",
        "CIFARAcc = CIFARmodel.evaluate(test_images,  test_labels, verbose=2)[1]\n",
        "print(\"Test Accuracy:\", CIFARAcc)\n",
        "\n",
        "\n",
        "# Save\n",
        "model_name = 'mlp_cifar.h5'\n",
        "retrainedMLP.save(model_name, save_format='h5')\n",
        "# Save\n",
        "model_name = 'cnn_cifar.h5'\n",
        "retrainedCNN.save(model_name, save_format='h5')\n",
        "# Save\n",
        "model_name = 'specialized_cifar.h5'\n",
        "CIFARmodel.save(model_name, save_format='h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "_riPiWZ5hFQs",
        "outputId": "b2cff714-a6f8-496b-e846-d2aa0989ce5b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# build MLP model with 3 layers\\nretrainedMLP = tf.keras.models.Sequential()\\n#Flatten\\nretrainedMLP.add(tf.keras.layers.Flatten(input_shape=(32,32,3)))\\n\\n#Layer 1\\nretrainedMLP.add(tf.keras.layers.Dense(\\n    units=128,\\n    activation=tf.keras.activations.relu,\\n    kernel_regularizer=tf.keras.regularizers.l2(0.002)\\n))\\n\\n# Hidden layer\\nretrainedMLP.add(tf.keras.layers.Dense(\\n    units=128,\\n    activation=tf.keras.activations.relu,\\n    kernel_regularizer=tf.keras.regularizers.l2(0.002)\\n))\\n\\n# Output layer\\nretrainedMLP.add(tf.keras.layers.Dense(\\n    units=10, # number of labels\\n    activation=tf.keras.activations.softmax\\n))\\n\\nretrainedMLP.summary()\\n\\nretrainedMLP.compile(\\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n    loss=\\'sparse_categorical_crossentropy\\',\\n    metrics=[\\'accuracy\\']\\n)\\n\\ntraining_history = retrainedMLP.fit(\\n    train_images,\\n    train_labels,\\n    epochs=10,\\n    callbacks=[tensorboard_callback],\\n)\\n\\n# Retrained MLP Accuracy\\ntestAcc = retrainedMLP.evaluate(test_images, test_labels)[1]\\nprint(\\'Test accuracy: \\', testAcc)\\n\\n\\n\\n# build CNN model\\nretrainedCNN = tf.keras.models.Sequential()\\n\\n#2D Convolution layer - 32 filters, 3x3 kernel, ReLU activation, padding with same values\\nretrainedCNN.add(tf.keras.layers.Conv2D(\\n    filters = 32,\\n    kernel_size = (3,3),\\n    padding=\\'same\\',\\n    activation=tf.keras.activations.relu,\\n    data_format=\\'channels_last\\',\\n    input_shape=(32, 32, 3),\\n))\\n\\n#Max pooling layer - 2x2 kernel, 2 stride\\nretrainedCNN.add(tf.keras.layers.MaxPool2D(\\n    pool_size=(2, 2),\\n    strides=2,\\n    padding=\\'valid\\',\\n    data_format=\\'channels_last\\',\\n))\\n\\n#2D Convolution layer - 64 filters, 3x3 kernel, ReLU activation, padding with same values\\nretrainedCNN.add(tf.keras.layers.Conv2D(\\n    filters = 64,\\n    kernel_size = (3, 3),\\n    padding=\\'same\\',\\n    activation=tf.keras.activations.relu,\\n    data_format=\\'channels_last\\',\\n))\\n\\n#Max pooling layer - 2x2 kernel, 2 stride\\nretrainedCNN.add(tf.keras.layers.MaxPool2D(\\n    pool_size=(2, 2),\\n    strides=2,\\n    padding=\\'valid\\',\\n    data_format=\\'channels_last\\',\\n))\\n\\n#Flatten layer\\nretrainedCNN.add(tf.keras.layers.Flatten())\\n\\n#Dense layer - 128 nodes output, ReLU activation\\nretrainedCNN.add(tf.keras.layers.Dense(\\n    units=128, # number of nodes\\n    activation=tf.keras.activations.relu\\n))\\n#Dense layer - 10 nodes output, Softmax activation\\nretrainedCNN.add(tf.keras.layers.Dense(\\n    units=10, # number of labels\\n    activation=tf.keras.activations.softmax\\n))\\n\\nretrainedCNN.summary()\\n\\nretrainedCNN.compile(\\n              optimizer=\\'adam\\', \\n              loss=\\'sparse_categorical_crossentropy\\', \\n              metrics=[\\'accuracy\\'])\\n\\ntraining_history = retrainedCNN.fit(\\n    train_images,\\n    train_labels,\\n    epochs=10,\\n    callbacks=[tensorboard_callback],\\n)\\n\\n# Retrained CNN Accuracy\\nCNNAcc = retrainedCNN.evaluate(test_images, test_labels)[1]\\nprint(\\'Test Accuracy: \\', CNNAcc)\\n\\n\\n# Build specialized CIFAR CNN\\nCIFARmodel = tf.keras.models.Sequential()\\nCIFARmodel.add(tf.keras.layers.Conv2D(32, (3, 3), activation=\\'relu\\', input_shape=(32, 32, 3)))\\nCIFARmodel.add(tf.keras.layers.MaxPooling2D((2, 2)))\\nCIFARmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\\'relu\\'))\\nCIFARmodel.add(tf.keras.layers.MaxPooling2D((2, 2)))\\nCIFARmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\\'relu\\'))\\nCIFARmodel.add(tf.keras.layers.Flatten())\\nCIFARmodel.add(tf.keras.layers.Dense(64, activation=\\'relu\\'))\\nCIFARmodel.add(tf.keras.layers.Dense(10))\\n\\nCIFARmodel.summary()\\n\\nCIFARmodel.compile(\\n              optimizer=\\'adam\\',\\n              loss=\\'sparse_categorical_crossentropy\\',\\n              metrics=[\\'accuracy\\'])\\n\\ntraining_history = CIFARmodel.fit(\\n    train_images, \\n    train_labels, \\n    epochs=10, \\n    validation_data=(test_images, test_labels),\\n    callbacks=[tensorboard_callback],\\n)\\n\\n# Specialized CIFAR CNN Accuracy\\nCIFARAcc = CIFARmodel.evaluate(test_images,  test_labels, verbose=2)[1]\\nprint(\"Test Accuracy:\", CIFARAcc)\\n\\n\\n# Save\\nmodel_name = \\'mlp_cifar.h5\\'\\nretrainedMLP.save(model_name, save_format=\\'h5\\')\\n# Save\\nmodel_name = \\'cnn_cifar.h5\\'\\nretrainedCNN.save(model_name, save_format=\\'h5\\')\\n# Save\\nmodel_name = \\'specialized_cifar.h5\\'\\nCIFARmodel.save(model_name, save_format=\\'h5\\')\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART 3**\n",
        "\n",
        "*Improved CNN Model Structure*:\n",
        "\n",
        "      Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        "\n",
        "      conv2d_12 (Conv2D)               (None, 30, 30, 32)        896       \n",
        "                                                                 \n",
        "      max_pooling2d_10 (MaxPooling2D)  (None, 15, 15, 32)        0         \n",
        "                                                           \n",
        "                                                                 \n",
        "      conv2d_13 (Conv2D)               (None, 13, 13, 64)        18496     \n",
        "                                                                 \n",
        "      max_pooling2d_11 (MaxPooling2D)  (None, 6, 6, 64)          0         \n",
        "                                                            \n",
        "                                                                 \n",
        "      conv2d_14 (Conv2D)               (None, 4, 4, 64)          36928     \n",
        "                                                                 \n",
        "      flatten_7 (Flatten)              (None, 1024)              0         \n",
        "                                                                 \n",
        "      dropout_1 (Dropout)              (None, 1024)              0         \n",
        "                                                                 \n",
        "      dense_17 (Dense)                 (None, 1024)              1049600   \n",
        "                                                                 \n",
        "      dense_18 (Dense)                 (None, 64)                65600     \n",
        "                                                                 \n",
        "      dense_19 (Dense)                 (None, 10)                650\n",
        "\n",
        "*Improved CNN Accuracy*:\n",
        "`Test accuracy:  `\n"
      ],
      "metadata": {
        "id": "p9RuyUDx1pwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PART 3\n",
        "'''\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import datetime\n",
        "import platform\n",
        "\n",
        "# Build improved CIFAR CNN\n",
        "betterCIFAR = tf.keras.models.Sequential()\n",
        "betterCIFAR.add(tf.keras.layers.Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
        "betterCIFAR.add(tf.keras.layers.Conv2D(32, (3, 3)))\n",
        "\n",
        "betterCIFAR.add(tf.keras.layers.MaxPooling2D((2, 2), strides=2, padding='valid'))\n",
        "betterCIFAR.add(tf.keras.layers.Conv2D(16, (3, 3)))\n",
        "betterCIFAR.add(tf.keras.layers.Conv2D(16, (3, 3)))\n",
        "betterCIFAR.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same'))\n",
        "\n",
        "betterCIFAR.add(tf.keras.layers.Flatten())\n",
        "betterCIFAR.add(tf.keras.layers.Dense(64, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.002)))\n",
        "betterCIFAR.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "betterCIFAR.summary()\n",
        "\n",
        "betterCIFAR.compile(\n",
        "              optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "training_history = betterCIFAR.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    validation_data=(test_images, test_labels),\n",
        "    callbacks=[tensorboard_callback],\n",
        ")\n",
        "\n",
        "# Improved CIFAR CNN Accuracy\n",
        "betterAcc = betterCIFAR.evaluate(test_images,  test_labels, verbose=2)[1]\n",
        "print(\"Test Accuracy:\", betterAcc)\n",
        "\n",
        "# Confusion Matrix and Error Examples\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "predicted_labels = np.argmax(betterCIFAR.predict(test_images), axis=1)\n",
        "cm = confusion_matrix(test_labels.flatten(), predicted_labels)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Save\n",
        "model_name = 'improved_cifar_cnn.h5'\n",
        "betterCIFAR.save(model_name, save_format='h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3cfqEqW1m63",
        "outputId": "f6474ac5-0c00-44bc-d96e-df56d9c086c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_21 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 14, 14, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 12, 12, 16)        4624      \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 10, 10, 16)        2320      \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 10, 10, 32)        4640      \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                204864    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 227242 (887.66 KB)\n",
            "Trainable params: 227242 (887.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            " 302/1563 [====>.........................] - ETA: 1:33 - loss: 2.0063 - accuracy: 0.3328"
          ]
        }
      ]
    }
  ]
}
